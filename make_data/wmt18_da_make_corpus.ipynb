{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_HOME = '/ahc/work3/kosuke-t/data/WMT/newstest2018-humaneval/analysis/'\n",
    "DARR_HOME = '/ahc/work3/kosuke-t/data/WMT/wmt18-metrics-task-package/manual-evaluation/RR-seglevel.csv'\n",
    "SRC_HOME = '/ahc/work3/kosuke-t/data/WMT/wmt18-metrics-task-package/source-system-outputs/wmt18-submitted-data/txt/sources'\n",
    "REF_HOME = '/ahc/work3/kosuke-t/data/WMT/wmt18-metrics-task-package/source-system-outputs/wmt18-submitted-data/txt/references'\n",
    "HYP_HOME = '/ahc/work3/kosuke-t/data/WMT/wmt18-metrics-task-package/source-system-outputs/wmt18-submitted-data/txt/system-outputs/newstest2018'\n",
    "SAVE_PATH_DARR = '/ahc/work3/kosuke-t/data/WMT/wmt18_darr.pkl'\n",
    "SAVE_PATH_DA = '/ahc/work3/kosuke-t/data/WMT/wmt18_da.pkl'\n",
    "\n",
    "langs = ['cs-en', 'de-en', 'et-en', 'fi-en', 'ru-en', 'tr-en', 'zh-en', \n",
    "         'en-cs', 'en-de', 'en-et', 'en-fi', 'en-ru', 'en-tr', 'en-zh']\n",
    "\n",
    "# systems = {'cs-en':['CUNI-Transformer.5560', \n",
    "#                     'online-A.0', \n",
    "#                     'online-B.0', \n",
    "#                     'online-G.0', \n",
    "#                     'uedin.5561'], \n",
    "#            'de-en':[], \n",
    "#            'et-en':[], \n",
    "#            'fi-en':[], \n",
    "#            'ru-en':[], \n",
    "#            'tr-en':[], \n",
    "#            'zh-en':[], \n",
    "#            'en-cs':[], \n",
    "#            'en-de':[], \n",
    "#            'en-et':[], \n",
    "#            'en-fi':[], \n",
    "#            'en-ru':[], \n",
    "#            'en-tr':[], \n",
    "#            'en-zh':[]}\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from  tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    data = []\n",
    "    with open(filename, mode='r', encoding='utf-8') as r:\n",
    "        data = r.read().split(os.linesep)\n",
    "        if data[-1] == '':\n",
    "            data.pop(-1)\n",
    "    return data\n",
    "\n",
    "SRC_files = {lang:load_file(os.path.join(SRC_HOME, 'newstest2018-{0}{1}-src.{0}'.format(lang.split('-')[0], lang.split('-')[1])))  for lang in langs}\n",
    "REF_files = {lang:load_file(os.path.join(REF_HOME, 'newstest2018-{0}{1}-ref.{1}'.format(lang.split('-')[0], lang.split('-')[1]))) for lang in langs}\n",
    "HYP_files = {lang:{} for lang in langs}\n",
    "\n",
    "for lang in langs:\n",
    "    for fname in os.listdir(os.path.join(HYP_HOME, lang)):\n",
    "        if not fname.startswith('newstest2018'):\n",
    "            continue\n",
    "        # extract system id from fname\n",
    "        system_id = copy.deepcopy(fname).replace('newstest2018.', '').replace('.{}'.format(lang), '')\n",
    "        # add\n",
    "        HYP_files[lang][system_id] = load_file(os.path.join(os.path.join(HYP_HOME, lang), fname))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â†“DARR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "326853it [00:00, 462832.93it/s]\n"
     ]
    }
   ],
   "source": [
    "DArr = load_file(DARR_HOME)\n",
    "corpus = []\n",
    "for idx, da_data in enumerate(DArr):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    lang = da_data.split(' ')[0]\n",
    "    sid = int(da_data.split(' ')[2])\n",
    "    better_sys = da_data.split(' ')[3]\n",
    "    worse_sys = da_data.split(' ')[4]\n",
    "    corpus.append({'lang': lang, \n",
    "                   'src': SRC_files[lang][sid-1], \n",
    "                   'ref': REF_files[lang][sid-1], \n",
    "                   'hyp1': HYP_files[lang][better_sys][sid-1], \n",
    "                   'hyp2': HYP_files[lang][worse_sys][sid-1], \n",
    "                   'better':'hyp1'})\n",
    "print('saving {}'.format(SAVE_PATH_DARR))\n",
    "with open(SAVE_PATH_DARR, mode='wb') as w:\n",
    "    pickle.dump(corpus, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DA for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_good_redup = {lang: os.path.join(DA_HOME, 'ad-{}-good-stnd-redup.csv'.format(lang.replace('-', ''))) for lang in langs}\n",
    "filename_seg_scores = {lang: os.path.join(DA_HOME, 'ad-seg-scores-{}.csv'.format(lang)) for lang in langs}\n",
    "\n",
    "DA_data_good_redup = {lang: load_file(f) for lang, f in filename_good_redup.items()}\n",
    "DA_data_seg_scores = {lang: load_file(f) for lang, f in filename_seg_scores.items()}\n",
    "\n",
    "def make_corpus_good_stnd_redup(langs, DA_data):\n",
    "    corpus = []\n",
    "    type_set = set()\n",
    "    for lang in langs:\n",
    "        for idx, row in enumerate(DA_data[lang]):\n",
    "            if idx == 0:\n",
    "                continue\n",
    "\n",
    "            type_id = row.split('\\t')[8]\n",
    "            score = float(row.split('\\t')[-2])\n",
    "            sid = int(row.split('\\t')[9])\n",
    "            system_id = row.split('\\t')[6]\n",
    "\n",
    "            type_set.add(type_id)\n",
    "\n",
    "            if type_id != 'SYSTEM':\n",
    "                continue\n",
    "\n",
    "            corpus.append({'lang':lang,\n",
    "                           'src':SRC_files[lang][sid-1],\n",
    "                           'ref':REF_files[lang][sid-1],\n",
    "                           'hyp':HYP_files[lang][system_id][sid-1],\n",
    "                           'label':score})\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def make_corpus_seg_scores(langs, DA_data):\n",
    "    corpus = []\n",
    "    for lang in langs:\n",
    "        for idx, row in enumerate(DA_data[lang]):\n",
    "            if idx == 0:\n",
    "                continue\n",
    "            system_id = row.split(' ')[0]\n",
    "            sid = int(row.split(' ')[1])\n",
    "            score = float(row.split(' ')[3])\n",
    "            n = int(row.split(' ')[4])\n",
    "            if system_id == 'HUMAN':\n",
    "#                 print(score)\n",
    "                continue\n",
    "            \n",
    "            corpus.append({'lang':lang,\n",
    "                           'src':SRC_files[lang][sid-1],\n",
    "                           'ref':REF_files[lang][sid-1],\n",
    "                           'hyp':HYP_files[lang][system_id][sid-1],\n",
    "                           'label':score})\n",
    "    return corpus\n",
    "\n",
    "corpus_good_redup = make_corpus_good_stnd_redup(langs, DA_data_good_redup)\n",
    "corpus_seg_scores = make_corpus_seg_scores(langs, DA_data_seg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SYS SID RAW.SCR Z.SCR N ',\n",
       " 'uedin.5766 638 99.5 0.970839129075777 2 ',\n",
       " 'uedin.5766 2079 80.6666666666667 0.256703691523479 3 ',\n",
       " 'uedin.5766 1419 89.6666666666667 0.887826348036053 3 ',\n",
       " 'uedin.5766 1154 100 1.4614885904276 2 ']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('good redup')\n",
    "print('-- corpus size for each language pair ---')\n",
    "for lang in langs:\n",
    "    for corpus in corpus_good_redupre\n",
    "\n",
    "print()\n",
    "\n",
    "print('seg scores')\n",
    "print('-- corpus size for each language pair ---')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326852"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LP SID BETTER WORSE',\n",
       " 'cs-en newstest2018 593 CUNI-Transformer.5560 online-B.0',\n",
       " 'cs-en newstest2018 344 CUNI-Transformer.5560 online-B.0',\n",
       " 'cs-en newstest2018 345 online-G.0 CUNI-Transformer.5560',\n",
       " 'cs-en newstest2018 346 uedin.5561 online-A.0']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DArr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- corpus size for language pair ---\n",
      "cs-en:11154\n",
      "de-en:43845\n",
      "et-en:25625\n",
      "fi-en:16589\n",
      "ru-en:15678\n",
      "tr-en:16921\n",
      "zh-en:28819\n",
      "en-cs:9781\n",
      "en-de:13208\n",
      "en-et:15759\n",
      "en-fi:9708\n",
      "en-ru:25641\n",
      "en-tr:3491\n",
      "en-zh:29168\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265387"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11154+43845+25625+16589+15678+16921+28819+9781+13208+15759+9708+25641+3491+29168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138199"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "147691-9492"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA\tceseng5002\tcs\ten\tad\tNA\tuedin.5561\tNA\tSYSTEM\t2545\t-0.361464469491382\t128.092999935\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['eng'], ['ces'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
