{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0428 16:49:25.477610 140186253354752 file_utils.py:41] PyTorch version 1.3.1 available.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import argparse\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.stats import pearsonr as pr\n",
    "from scipy.stats import spearmanr as sr\n",
    "import copy\n",
    "import pandas as pd\n",
    "import difflib\n",
    "from transformers import *\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from apex import amp\n",
    "from torch import optim\n",
    "from typing import Tuple\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import nn\n",
    "from shutil import rmtree\n",
    "import logging\n",
    "random.seed(77)\n",
    "torch.manual_seed(77)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    def __init__(self):\n",
    "        self.data_home = '/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA'\n",
    "        self.exp_name = 'multi-BERT_15'\n",
    "        self.dump_path = '/ahc/work3/kosuke-t/SRHDA/transformers/log/'\n",
    "        self.data_dirs = {'src_train':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/train.src', \n",
    "                          'src_valid':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/valid.src', \n",
    "                          'src_test':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/test.src', \n",
    "                          'ref_train':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/train.ref', \n",
    "                          'ref_valid':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/valid.ref', \n",
    "                          'ref_test':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/test.ref', \n",
    "                          'hyp_train':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/train.hyp', \n",
    "                          'hyp_valid':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/valid.hyp', \n",
    "                          'hyp_test':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/test.hyp', \n",
    "                          'label_train':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/train.label', \n",
    "                          'label_valid':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/valid.label', \n",
    "                          'label_test':'/ahc/work3/kosuke-t/data/SRHDA/WMT15_17_DA/test.label'\n",
    "                         }\n",
    "    \n",
    "        self.dump_path = os.path.join(self.dump_path, self.exp_name)\n",
    "        if not os.path.isdir(args.dump_path):\n",
    "            os.makedirs(args.dump_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "string = \"Hello, my dog is cute\" * 50\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "model.cuda()\n",
    "input_ids = torch.tensor([[[tokenizer.encode(string, add_special_tokens=True)*1000]*100]*50])  # Batch size 1\n",
    "input_ids.cuda()\n",
    "import pdb;pdb.set_trace()\n",
    "outputs = model(input_ids)\n",
    "\n",
    "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# x = torch.ones(3,3)\n",
    "# print(x)\n",
    "# x_list = [2,2]\n",
    "# x[0,] = torch.FloatTensor(x_list)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "multiBERT_all_hyp_src_hyp_ref\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.752\t0.572.\t0.488\t0.15\n",
      "-----------\n",
      "multiBERT_all_hyp_src_ref\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.736\t0.545.\t0.487\t0.11\n",
      "-----------\n",
      "multiBERT_all_hyp_src\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.611\t0.375.\t0.37\t0.01\n",
      "-----------\n",
      "multiBERT_all_hyp_ref\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.738\t0.558.\t0.449\t0.20\n",
      "-----------\n",
      "multiBERT_15_hyp_src_hyp_ref\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.728\t0.535.\t0.494\t0.08\n",
      "-----------\n",
      "multiBERT_15_hyp_src_ref\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.686\t0.512.\t0.423\t0.18\n",
      "-----------\n",
      "multiBERT_15_hyp_src\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.539\t0.339.\t0.316\t0.07\n",
      "-----------\n",
      "multiBERT_15_hyp_ref\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.672\t0.493.\t0.384\t0.22\n",
      "-----------\n",
      "multiBERT_halved_hyp_src_hyp_ref\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.658\t0.464.\t0.372\t0.20\n",
      "-----------\n",
      "multiBERT_halved_hyp_src_ref\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.659\t0.462.\t0.404\t0.13\n",
      "-----------\n",
      "multiBERT_halved_hyp_src\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.503\t0.344.\t0.269\t0.22\n",
      "-----------\n",
      "multiBERT_halved_hyp_ref\n",
      "All\tDA >= 0.0\tDA<0.0\tRD\n",
      "0.649\t0.441.\t0.359\t0.19\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from scipy.stats import pearsonr as pr\n",
    "from scipy.stats import spearmanr as sr\n",
    "import numpy as np\n",
    "\n",
    "def calc_pearson(pred, true):\n",
    "    try:\n",
    "        r, p_value = pr(np.asarray(pred), np.asarray(true))\n",
    "    except ValueError:\n",
    "        r = -1.0\n",
    "    return r\n",
    "\n",
    "EXP_NAMES = ['multiBERT_all_hyp_src_hyp_ref', \n",
    "             'multiBERT_all_hyp_src_ref', \n",
    "             'multiBERT_all_hyp_src',\n",
    "             'multiBERT_all_hyp_ref',\n",
    "             'multiBERT_15_hyp_src_hyp_ref', \n",
    "             'multiBERT_15_hyp_src_ref', \n",
    "             'multiBERT_15_hyp_src',\n",
    "             'multiBERT_15_hyp_ref',\n",
    "             'multiBERT_halved_hyp_src_hyp_ref', \n",
    "             'multiBERT_halved_hyp_src_ref', \n",
    "             'multiBERT_halved_hyp_src',\n",
    "             'multiBERT_halved_hyp_ref',]\n",
    "\n",
    "datadir = '/ahc/work3/kosuke-t/SRHDA/transformers/log/'\n",
    "for exp_name in EXP_NAMES:\n",
    "    data_path = os.path.join(os.path.join(datadir, exp_name), '1')\n",
    "    result_file = os.path.join(data_path, 'result.pkl')\n",
    "    with open(result_file, mode='rb') as r:\n",
    "        results = pickle.load(r)\n",
    "    best_val_epoch = 0\n",
    "    best_val_pearson = 0\n",
    "\n",
    "    for e, p_val in enumerate(results['valid']['pearson']):\n",
    "        if best_val_pearson < p_val:\n",
    "            best_val_pearson = p_val\n",
    "            best_val_epoch = e\n",
    "\n",
    "    highs = {'pred':[], 'true':[]}\n",
    "    lows = {'pred':[], 'true':[]}\n",
    "    for pred, true in zip(results['test']['pred'][best_val_epoch], results['test']['true'][best_val_epoch]):\n",
    "        if true >= 0.0:\n",
    "            highs['pred'].append(pred)\n",
    "            highs['true'].append(true)\n",
    "        else:\n",
    "            lows['pred'].append(pred)\n",
    "            lows['true'].append(true)\n",
    "\n",
    "    print('-----------')\n",
    "    print(exp_name)\n",
    "    print('All\\tDA >= 0.0\\tDA<0.0\\tRD')\n",
    "    print('{:.3f}\\t{:.3f}.\\t{:.3}\\t{:.2f}'.format(results['test']['pearson'][best_val_epoch], \n",
    "                                  calc_pearson(highs['pred'], highs['true']), \n",
    "                                  calc_pearson(lows['pred'], lows['true']), \n",
    "                                  (calc_pearson(highs['pred'], highs['true'])-calc_pearson(lows['pred'], lows['true']))*100/calc_pearson(highs['pred'], highs['true'])\n",
    "                                 )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.06615722924470901, -0.7326883673667908, 0.4631434679031372]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
